{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel oluşturma ve oluşturulan modelin test edilmesi\\n\\nreduced_data.csv dosyasını okur ve bu dosya ile 4 tane model oluşturur.\\nTest dosyalarını okur ve özniteliklerin sıklıklarıyla tablo oluşturur.\\n\\nKullanılan sınıflandırma algoritmalar:\\n1- Linear Support Vector \\n2- K-Nearest Neighbors\\n3- Gaussian Naive Bayes\\n4- Stochastic Gradient Descent\\n5- Rocchio\\n6- Multinomial Naive Bayes\\n\\nBu algoritmalardan en iyi sonucu veren Multinominal Naive Bayes oldu.\\nYüksek ihtimalle bu modelde ezberleme söz konusu olabilir bu kadar yüksek sonuçlar beklemiyordum.\\n\\n'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model oluşturma ve oluşturulan modelin test edilmesi\n",
    "\n",
    "reduced_data.csv dosyasını okur ve bu dosya ile 4 tane model oluşturur.\n",
    "Test dosyalarını okur ve özniteliklerin sıklıklarıyla tablo oluşturur.\n",
    "\n",
    "Kullanılan sınıflandırma algoritmalar:\n",
    "1- Linear Support Vector \n",
    "2- K-Nearest Neighbors\n",
    "3- Gaussian Naive Bayes\n",
    "4- Stochastic Gradient Descent\n",
    "5- Rocchio\n",
    "6- Multinomial Naive Bayes\n",
    "\n",
    "Bu algoritmalardan en iyi sonucu veren Multinominal Naive Bayes oldu.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import grpc\n",
    "import sys\n",
    "import zemberek_grpc.language_id_pb2 as z_langid\n",
    "import zemberek_grpc.language_id_pb2_grpc as z_langid_g\n",
    "import zemberek_grpc.normalization_pb2 as z_normalization\n",
    "import zemberek_grpc.normalization_pb2_grpc as z_normalization_g\n",
    "import zemberek_grpc.preprocess_pb2 as z_preprocess\n",
    "import zemberek_grpc.preprocess_pb2_grpc as z_preprocess_g\n",
    "import zemberek_grpc.morphology_pb2 as z_morphology\n",
    "import zemberek_grpc.morphology_pb2_grpc as z_morphology_g\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "channel = grpc.insecure_channel('localhost:1234')\n",
    "normalization_stub = z_normalization_g.NormalizationServiceStub(channel)\n",
    "preprocess_stub = z_preprocess_g.PreprocessingServiceStub(channel)\n",
    "morphology_stub = z_morphology_g.MorphologyServiceStub(channel)\n",
    "\n",
    "def reportDf(report):\n",
    "    report = [x.split(' ') for x in report.split('\\n')]\n",
    "    header = ['Class Name']+[x for x in report[0] if x!='']\n",
    "    values = []\n",
    "    for row in report[1:-5]:\n",
    "        row = [value for value in row if value!='']\n",
    "        if row!=[]:\n",
    "            values.append(row)\n",
    "    df = pd.DataFrame(data = values, columns = header)\n",
    "    del df['support']\n",
    "    avarages = [\"ortalama\"]\n",
    "    for i in range(0,3):\n",
    "        avarages.append(round(pd.to_numeric(df[['precision','recall','f1-score']].iloc[i]).mean(),2))  \n",
    "    df.loc[df.index.max()+1] = avarages\n",
    "    df = df.transpose()\n",
    "    df.columns=list(df.iloc[0])\n",
    "    df = df[1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(i):\n",
    "    response = preprocess_stub.Tokenize(z_preprocess.TokenizationRequest(input=i))\n",
    "    return response.tokens\n",
    "\n",
    "def normalize(i):\n",
    "    response = normalization_stub.Normalize(z_normalization.NormalizationRequest(input=i))\n",
    "    return response\n",
    "\n",
    "def analyze(i):\n",
    "    response = morphology_stub.AnalyzeSentence(z_morphology.SentenceAnalysisRequest(input=i))\n",
    "    return response;\n",
    "\n",
    "def fix_decode(text):\n",
    "    \"\"\"Pass decode.\"\"\"\n",
    "    if sys.version_info < (3, 0):\n",
    "        return text.decode('utf-8')\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "stop_words = list(map(lambda x: x.replace(\"\\n\",\"\").encode(\"utf-8\"), open(\"stop-words.txt\",encoding=\"iso-8859-9\").readlines()))\n",
    "def isStopWord(word):\n",
    "    if word == \"UNK\":\n",
    "        return True\n",
    "    return word in stop_words\n",
    "\n",
    "def preprocess(document):\n",
    "    tokenized = fix_decode(tokenize(normalize(document).normalized_input))\n",
    "    output = []\n",
    "    for i in tokenized:\n",
    "        if i.type == 'Word':\n",
    "            lemma = analyze(i.token).results[0].best.lemmas[0]\n",
    "            #print(\"lemma(%s)=%s\"%(i.token,lemma))\n",
    "            if not isStopWord(lemma):\n",
    "                output.append(str(lemma))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../reduced_data.csv\")\n",
    "data = data[data.columns[~data.columns.isin(['Unnamed: 0'])]]\n",
    "feature_names = data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(root_path):\n",
    "    ignore = ['.DS_Store']\n",
    "    folders = set(os.listdir(root_path))-set(ignore)\n",
    "    txt_files = []\n",
    "    for folder in folders:\n",
    "        folder_path = \"%s/%s/\" % (root_path,folder)\n",
    "        for file in set(os.listdir(folder_path))-set(ignore):\n",
    "            file_path = \"%s/%s/%s\" %(root_path,folder,file)\n",
    "            txt_files.append(file_path)\n",
    "    return txt_files\n",
    "\n",
    "def getPreprocessedDocument(path):\n",
    "    f_in = open(path,encoding=\"iso-8859-9\").read()\n",
    "    doc = preprocess(f_in)\n",
    "    data = [0]*(len(feature_names))\n",
    "    for index,word in enumerate(feature_names):\n",
    "        data[index] = doc.count(word)\n",
    "    data[-1] = doc_type = path.split(\"/\")[3]\n",
    "    return data\n",
    "\n",
    "\n",
    "test_files = getFiles(root_path = \"../data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for test_file in test_files:\n",
    "    test_data.append(getPreprocessedDocument(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_data,columns=list(feature_names))\n",
    "test.to_csv(\"../test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.columns[~data.columns.isin(['class'])]]\n",
    "y = data['class']\n",
    "test_x = test[test.columns[~test.columns.isin(['class'])]]\n",
    "test_y = test['class']\n",
    "target_names = list(set(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazin</th>\n",
       "      <th>saglik</th>\n",
       "      <th>ekonomi</th>\n",
       "      <th>spor</th>\n",
       "      <th>ortalama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          magazin saglik ekonomi  spor ortalama\n",
       "precision    0.96   0.96    0.97  0.98     0.97\n",
       "recall       0.97   0.96    0.95  0.99     0.96\n",
       "f1-score     0.97   0.96    0.96  0.98     0.96"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "svc_model = LinearSVC(random_state=12)\n",
    "svc_model = svc_model.fit(x, y)\n",
    "pred = svc_model.predict(test_x)\n",
    "\n",
    "df = reportDf(classification_report(test_y, pred, target_names=target_names))\n",
    "df.to_csv(\"../reports/linearsvc.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazin</th>\n",
       "      <th>saglik</th>\n",
       "      <th>ekonomi</th>\n",
       "      <th>spor</th>\n",
       "      <th>ortalama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          magazin saglik ekonomi  spor ortalama\n",
       "precision    0.98   0.46    1.00  0.81     0.81\n",
       "recall       0.66   0.94    0.30  0.80     0.67\n",
       "f1-score     0.79   0.62    0.46  0.81     0.59"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "neigh.fit(x, y)\n",
    "\n",
    "pred = neigh.predict(test_x)\n",
    "\n",
    "df = reportDf(classification_report(test_y, pred, target_names=target_names))\n",
    "df.to_csv(\"../reports/kneighborsclassifier.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazin</th>\n",
       "      <th>saglik</th>\n",
       "      <th>ekonomi</th>\n",
       "      <th>spor</th>\n",
       "      <th>ortalama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          magazin saglik ekonomi  spor ortalama\n",
       "precision    0.83   0.96    0.76  0.86     0.81\n",
       "recall       0.79   0.85    0.81  0.95      0.9\n",
       "f1-score     0.81   0.90    0.79  0.90     0.79"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(x, y)\n",
    "pred = gnb.predict(test_x)\n",
    "\n",
    "df = reportDf(classification_report(test_y, pred, target_names=target_names))\n",
    "df.to_csv(\"../reports/gaussiannb.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazin</th>\n",
       "      <th>saglik</th>\n",
       "      <th>ekonomi</th>\n",
       "      <th>spor</th>\n",
       "      <th>ortalama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          magazin saglik ekonomi  spor ortalama\n",
       "precision    0.95   0.97    0.99  0.96     0.96\n",
       "recall       0.97   0.96    0.94  1.00     0.97\n",
       "f1-score     0.96   0.97    0.96  0.98     0.96"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd = clf.fit(x, y)\n",
    "pred = sgd.predict(test_x)\n",
    "\n",
    "df = reportDf(classification_report(test_y, pred, target_names=target_names))\n",
    "df.to_csv(\"../reports/sgdclassifier.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazin</th>\n",
       "      <th>saglik</th>\n",
       "      <th>ekonomi</th>\n",
       "      <th>spor</th>\n",
       "      <th>ortalama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          magazin saglik ekonomi  spor ortalama\n",
       "precision    0.95   0.52    0.96  1.00     0.85\n",
       "recall       0.76   0.97    0.68  0.62     0.72\n",
       "f1-score     0.85   0.68    0.79  0.77     0.81"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rocchio\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "rocchio = NearestCentroid(metric='euclidean')\n",
    "rocchio = rocchio.fit(x, y)\n",
    "pred = rocchio.predict(test_x)\n",
    "df = reportDf(classification_report(test_y, pred, target_names=target_names))\n",
    "df.to_csv(\"../reports/rocchio.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazin</th>\n",
       "      <th>saglik</th>\n",
       "      <th>ekonomi</th>\n",
       "      <th>spor</th>\n",
       "      <th>ortalama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          magazin saglik ekonomi  spor ortalama\n",
       "precision    0.94   1.00    0.99  1.00     0.96\n",
       "recall       0.99   0.99    0.96  0.99     0.99\n",
       "f1-score     0.96   0.99    0.97  0.99     0.97"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialNB = MultinomialNB()\n",
    "multinomialNB.fit(x,y)\n",
    "pred = multinomialNB.predict(test_x)\n",
    "df = reportDf(classification_report(test_y, pred, target_names=target_names))\n",
    "df.to_csv(\"../reports/multinomialnb.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(str_data):\n",
    "    doc =  preprocess(str_data)\n",
    "    print(doc)\n",
    "    data = [0]*(len(feature_names)-1)\n",
    "    for index,word in enumerate(list(set(feature_names)-set(['class']))):\n",
    "        data[index] = doc.count(word)\n",
    "    return data    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
